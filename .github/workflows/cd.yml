# .github/workflows/cd.yml
name: Continuous Deployment (CD)

on:
  push:
    branches: [main, Terraform]  # Allow CD on both main and Terraform branches
  workflow_dispatch:  # Allow manual trigger

jobs:
  # Run all CI checks first
  ci-checks:
    name: Run CI Checks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: "npm"
          cache-dependency-path: "backend/package-lock.json"

      - name: Install dependencies
        working-directory: backend
        run: npm ci

      - name: Run linter
        working-directory: backend
        run: npm run lint

      - name: Run tests
        working-directory: backend
        run: npm test
        env:
          NODE_ENV: test
          MONGODB_URI: ${{ secrets.TEST_MONGODB_URI }}

  # Security scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: ci-checks
    steps:
      - uses: actions/checkout@v4

      # Set up Docker Buildx
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Container scanning with Trivy
      - name: Build Docker image for scanning
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: momo-splitwise-backend:latest
          load: true
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Scan Docker image for vulnerabilities
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: "momo-splitwise-backend:latest"
          format: "table"
          exit-code: "1"
          ignore-unfixed: true
          severity: "CRITICAL"
          scan-type: "image"

      # IaC scanning with tfsec
      - name: Run tfsec
        uses: aquasecurity/tfsec-action@v1.0.0
        with:
          working_directory: terraform
          soft_fail: true

  # Build and push to Azure Container Registry
  build-and-push:
    name: Build and Push to ACR
    runs-on: ubuntu-latest
    needs: security-scan
    steps:
      - uses: actions/checkout@v4

      # Set up Docker Buildx
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Install Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Get ACR details from Azure
        id: get-acr
        run: |
          # Try to get ACR from Azure directly
          RG_NAME="${{ secrets.ACR_RESOURCE_GROUP }}"
          if [ -z "$RG_NAME" ]; then
            RG_NAME="momo-splitwise-prod-rg"
          fi
          
          # List ACRs in the resource group
          ACR_NAME=$(az acr list --resource-group "$RG_NAME" --query "[0].name" -o tsv 2>/dev/null || echo "")
          ACR_LOGIN_SERVER=$(az acr list --resource-group "$RG_NAME" --query "[0].loginServer" -o tsv 2>/dev/null || echo "")
          
          # Fallback to secrets if Azure query fails
          if [ -z "$ACR_NAME" ]; then
            ACR_NAME="${{ secrets.ACR_NAME }}"
          fi
          if [ -z "$ACR_LOGIN_SERVER" ]; then
            ACR_LOGIN_SERVER="${{ secrets.ACR_LOGIN_SERVER }}"
          fi
          
          # Final fallback to known correct values
          if [ -z "$ACR_NAME" ] || [ "$ACR_NAME" = "null" ]; then
            ACR_NAME="momosplitwiseprodacr"
          fi
          if [ -z "$ACR_LOGIN_SERVER" ] || [ "$ACR_LOGIN_SERVER" = "null" ]; then
            ACR_LOGIN_SERVER="momosplitwiseprodacr.azurecr.io"
          fi
          
          echo "acr_name=$ACR_NAME" >> $GITHUB_OUTPUT
          echo "acr_login_server=$ACR_LOGIN_SERVER" >> $GITHUB_OUTPUT
          echo "‚úÖ Using ACR: $ACR_NAME ($ACR_LOGIN_SERVER)"
        continue-on-error: true

      - name: Set ACR variables
        id: acr-vars
        run: |
          ACR_NAME="${{ secrets.ACR_NAME }}"
          ACR_LOGIN_SERVER="${{ secrets.ACR_LOGIN_SERVER }}"
          if [ -z "$ACR_NAME" ]; then
            ACR_NAME="${{ steps.get-acr.outputs.acr_name }}"
          fi
          if [ -z "$ACR_LOGIN_SERVER" ]; then
            ACR_LOGIN_SERVER="${{ steps.get-acr.outputs.acr_login_server }}"
          fi
          if [ -z "$ACR_NAME" ] || [ -z "$ACR_LOGIN_SERVER" ]; then
            echo "‚ùå ACR_NAME and ACR_LOGIN_SERVER must be set in GitHub secrets"
            exit 1
          fi
          echo "acr_name=$ACR_NAME" >> $GITHUB_OUTPUT
          echo "acr_login_server=$ACR_LOGIN_SERVER" >> $GITHUB_OUTPUT
          echo "image_tag=${ACR_LOGIN_SERVER}/momo-splitwise-backend:${GITHUB_SHA::8}" >> $GITHUB_OUTPUT
          echo "image_tag_latest=${ACR_LOGIN_SERVER}/momo-splitwise-backend:latest" >> $GITHUB_OUTPUT

      - name: Login to Azure Container Registry
        run: |
          az acr login --name ${{ steps.acr-vars.outputs.acr_name }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            ${{ steps.acr-vars.outputs.image_tag }}
            ${{ steps.acr-vars.outputs.image_tag_latest }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Output image details
        run: |
          echo "‚úÖ Image pushed successfully:"
          echo "  - ${{ steps.acr-vars.outputs.image_tag }}"
          echo "  - ${{ steps.acr-vars.outputs.image_tag_latest }}"

  # Deploy to Azure VM using Ansible
  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: build-and-push
    environment: production
    steps:
      - uses: actions/checkout@v4

      - name: Set up SSH
        run: |
          mkdir -p ~/.ssh
          chmod 700 ~/.ssh
          
          # Write SSH key using printf to preserve newlines properly
          # This ensures the key is written exactly as stored in the secret
          printf '%s\n' "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          
          # Verify the key file has proper format (check for BEGIN/END markers)
          if ! grep -q "BEGIN.*PRIVATE KEY" ~/.ssh/id_rsa; then
            echo "‚ùå SSH private key is missing BEGIN marker"
            echo "This usually means the SSH_PRIVATE_KEY secret is not properly formatted."
            echo "Key file preview (first 100 chars):"
            head -c 100 ~/.ssh/id_rsa || cat ~/.ssh/id_rsa | head -c 100
            echo ""
            echo "Please ensure SSH_PRIVATE_KEY secret includes:"
            echo "  - -----BEGIN ... PRIVATE KEY-----"
            echo "  - The key content"
            echo "  - -----END ... PRIVATE KEY-----"
            exit 1
          fi
          
          if ! grep -q "END.*PRIVATE KEY" ~/.ssh/id_rsa; then
            echo "‚ùå SSH private key is missing END marker"
            echo "Key file preview (last 100 chars):"
            tail -c 100 ~/.ssh/id_rsa || cat ~/.ssh/id_rsa | tail -c 100
            exit 1
          fi
          
          # Verify SSH key format using ssh-keygen
          if ! ssh-keygen -l -f ~/.ssh/id_rsa > /dev/null 2>&1; then
            echo "‚ùå SSH private key is invalid or corrupted"
            echo "Key file line count: $(wc -l < ~/.ssh/id_rsa)"
            echo "Key file size: $(wc -c < ~/.ssh/id_rsa) bytes"
            echo ""
            echo "First 3 lines:"
            head -3 ~/.ssh/id_rsa
            echo ""
            echo "Last 3 lines:"
            tail -3 ~/.ssh/id_rsa
            echo ""
            echo "Please verify the SSH_PRIVATE_KEY secret in GitHub Settings ‚Üí Secrets"
            exit 1
          fi
          
          # Configure SSH for better connection reliability
          cat >> ~/.ssh/config <<EOF
          Host ${{ secrets.APPLICATION_VM_IP }}
            User azureuser
            IdentityFile ~/.ssh/id_rsa
            StrictHostKeyChecking no
            UserKnownHostsFile ~/.ssh/known_hosts
            ConnectTimeout 60
            ServerAliveInterval 30
            ServerAliveCountMax 3
            TCPKeepAlive yes
          EOF
          
          # Add host to known_hosts
          ssh-keyscan -H ${{ secrets.APPLICATION_VM_IP }} >> ~/.ssh/known_hosts 2>/dev/null || true
          
          echo "‚úÖ SSH key configured successfully"
          KEY_TYPE=$(ssh-keygen -l -f ~/.ssh/id_rsa | awk '{print $4}')
          echo "‚úÖ SSH key type: $KEY_TYPE"

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Check VM Status
        run: |
          VM_IP="${{ secrets.APPLICATION_VM_IP }}"
          RG_NAME="${{ secrets.ACR_RESOURCE_GROUP }}"
          
          echo "üîç Checking VM status..."
          
          # Try to find VM by public IP
          if [ -n "$RG_NAME" ]; then
            echo "Checking VMs in resource group: $RG_NAME"
            az vm list --resource-group "$RG_NAME" --show-details --query '[].{Name:name, PowerState:powerState, PublicIP:publicIps}' -o table || echo "‚ö†Ô∏è Could not list VMs"
            
            # Check if any VM is stopped
            STOPPED_VMS=$(az vm list --resource-group "$RG_NAME" --show-details --query "[?powerState=='VM stopped'].name" -o tsv 2>/dev/null || echo "")
            if [ -n "$STOPPED_VMS" ]; then
              echo "‚ö†Ô∏è Warning: Found stopped VMs:"
              echo "$STOPPED_VMS"
              echo "Consider starting them if deployment fails"
            fi
          fi
          
          echo "Target VM IP: $VM_IP"
          echo ""

      - name: Get ACR details
        id: acr-details
        run: |
          RG_NAME="${{ secrets.ACR_RESOURCE_GROUP }}"
          if [ -z "$RG_NAME" ]; then
            RG_NAME="momo-splitwise-prod-rg"
          fi
          
          # Try to get ACR from Azure directly (most reliable)
          ACR_NAME=$(az acr list --resource-group "$RG_NAME" --query "[0].name" -o tsv 2>/dev/null || echo "")
          ACR_LOGIN_SERVER=$(az acr list --resource-group "$RG_NAME" --query "[0].loginServer" -o tsv 2>/dev/null || echo "")
          
          # Fallback to secrets
          if [ -z "$ACR_NAME" ] || [ "$ACR_NAME" = "null" ]; then
            ACR_NAME="${{ secrets.ACR_NAME }}"
          fi
          if [ -z "$ACR_LOGIN_SERVER" ] || [ "$ACR_LOGIN_SERVER" = "null" ]; then
            ACR_LOGIN_SERVER="${{ secrets.ACR_LOGIN_SERVER }}"
          fi
          
          # Final fallback to known correct values
          if [ -z "$ACR_NAME" ] || [ "$ACR_NAME" = "null" ]; then
            ACR_NAME="momosplitwiseprodacr"
            echo "‚ö†Ô∏è Using hardcoded ACR name: $ACR_NAME"
          fi
          if [ -z "$ACR_LOGIN_SERVER" ] || [ "$ACR_LOGIN_SERVER" = "null" ]; then
            ACR_LOGIN_SERVER="momosplitwiseprodacr.azurecr.io"
            echo "‚ö†Ô∏è Using hardcoded ACR login server: $ACR_LOGIN_SERVER"
          fi
          
          echo "acr_name=$ACR_NAME" >> $GITHUB_OUTPUT
          echo "acr_login_server=$ACR_LOGIN_SERVER" >> $GITHUB_OUTPUT
          echo "image_tag=${ACR_LOGIN_SERVER}/momo-splitwise-backend:${GITHUB_SHA::8}" >> $GITHUB_OUTPUT
          echo "image_tag_latest=${ACR_LOGIN_SERVER}/momo-splitwise-backend:latest" >> $GITHUB_OUTPUT
          echo "‚úÖ Using ACR: $ACR_NAME ($ACR_LOGIN_SERVER)"

      - name: Install Ansible
        run: |
          sudo apt-get update
          sudo apt-get install -y ansible

      - name: Install Ansible Docker collection
        run: |
          ansible-galaxy collection install community.docker

      - name: Test SSH connection
        run: |
          VM_IP="${{ secrets.APPLICATION_VM_IP }}"
          echo "üîç Testing SSH connection to $VM_IP..."
          
          # Test basic connectivity
          if ! timeout 10 ping -c 3 $VM_IP > /dev/null 2>&1; then
            echo "‚ö†Ô∏è Ping test failed, but continuing (ICMP may be blocked)"
          else
            echo "‚úÖ Ping test passed"
          fi
          
          # Test SSH port connectivity
          if ! timeout 10 nc -zv -w 5 $VM_IP 22 2>&1; then
            echo "‚ùå Cannot connect to SSH port 22 on $VM_IP"
            echo "This could indicate:"
            echo "  - VM is not running"
            echo "  - NSG rules are blocking SSH"
            echo "  - Public IP is incorrect"
            echo "  - Firewall is blocking the connection"
            exit 1
          else
            echo "‚úÖ SSH port 22 is reachable"
          fi
          
          # Test SSH authentication
          MAX_RETRIES=3
          RETRY_COUNT=0
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if timeout 60 ssh -o ConnectTimeout=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=~/.ssh/known_hosts azureuser@$VM_IP "echo 'SSH connection successful'" 2>&1; then
              echo "‚úÖ SSH authentication successful"
              break
            else
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "‚è≥ SSH connection attempt $RETRY_COUNT failed, retrying in 10 seconds..."
                sleep 10
              else
                echo "‚ùå SSH authentication failed after $MAX_RETRIES attempts"
                echo "Please verify:"
                echo "  - SSH_PRIVATE_KEY secret is correct"
                echo "  - VM is running and accessible"
                echo "  - NSG rules allow SSH from GitHub Actions IPs"
                exit 1
              fi
            fi
          done

      - name: Create Ansible inventory
        run: |
          mkdir -p ansible/inventory
          cat > ansible/inventory/production.yml <<EOF
          all:
            children:
              application:
                hosts:
                  application_vm:
                    ansible_host: ${{ secrets.APPLICATION_VM_IP }}
                    ansible_user: azureuser
                    ansible_ssh_private_key_file: ~/.ssh/id_rsa
                    ansible_ssh_common_args: '-o StrictHostKeyChecking=no -o ConnectTimeout=60 -o ServerAliveInterval=30 -o ServerAliveCountMax=3 -o TCPKeepAlive=yes'
            vars:
              ansible_python_interpreter: /usr/bin/python3
              ansible_connection: ssh
              ansible_ssh_retries: 3
              ansible_timeout: 60
          EOF

      - name: Create Ansible group vars
        run: |
          mkdir -p ansible/group_vars
          cat > ansible/group_vars/application.yml <<EOF
          ---
          acr_name: ${{ steps.acr-details.outputs.acr_name }}
          acr_resource_group: ${{ secrets.ACR_RESOURCE_GROUP }}
          acr_login_server: ${{ steps.acr-details.outputs.acr_login_server }}
          image_tag: ${{ steps.acr-details.outputs.image_tag_latest }}
          app_name: momo-splitwise
          app_environment: prod
          docker_compose_version: "2.24.0"
          docker_users:
            - azureuser
          EOF

      - name: Run Ansible deployment playbook
        working-directory: ansible
        run: |
          echo "üöÄ Starting Ansible deployment..."
          ansible-playbook \
            -i inventory/production.yml \
            playbooks/deploy.yml \
            --extra-vars "image_tag=${{ steps.acr-details.outputs.image_tag_latest }}" \
            -v
        continue-on-error: false

      - name: Verify deployment
        run: |
          echo "‚úÖ Deployment completed!"
          echo "Application Gateway URL: ${{ secrets.APPLICATION_GATEWAY_URL }}"
          echo "Health check endpoints:"
          echo "  - ${{ secrets.APPLICATION_GATEWAY_URL }}/health"
          echo "  - ${{ secrets.APPLICATION_GATEWAY_URL }}/api/health"
          
      - name: Health check verification
        run: |
          GATEWAY_URL="${{ secrets.APPLICATION_GATEWAY_URL }}"
          if [ -z "$GATEWAY_URL" ]; then
            echo "‚ö†Ô∏è APPLICATION_GATEWAY_URL secret not set, skipping health check"
            exit 0
          fi
          
          echo "üîç Checking health endpoint: ${GATEWAY_URL}/health"
          echo "‚ÑπÔ∏è Note: Application Gateway may take 15-30 minutes to fully provision after Terraform apply"
          
          MAX_RETRIES=20
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            # Try to get HTTP code with verbose error info
            HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" --max-time 10 --connect-timeout 5 "${GATEWAY_URL}/health" 2>&1 | tail -1 || echo "000")
            CURL_ERROR=$?
            
            if [ "$HTTP_CODE" = "200" ]; then
              echo "‚úÖ Health check passed! Application is responding."
              curl -s "${GATEWAY_URL}/health" | jq '.' || echo "Response received (non-JSON)"
              exit 0
            fi
            
            RETRY_COUNT=$((RETRY_COUNT + 1))
            
            # Provide more detailed error info
            if [ "$HTTP_CODE" = "000" ]; then
              echo "‚è≥ Health check attempt $RETRY_COUNT/$MAX_RETRIES failed (Connection timeout/unreachable)."
              echo "   This may indicate Application Gateway is still provisioning or network issues."
            else
              echo "‚è≥ Health check attempt $RETRY_COUNT/$MAX_RETRIES failed (HTTP $HTTP_CODE)."
            fi
            
            if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
              echo "   Retrying in 30 seconds..."
              sleep 30
            fi
          done
          
          echo "‚ùå Health check failed after $MAX_RETRIES attempts"
          echo "‚ö†Ô∏è Possible causes:"
          echo "   1. Application Gateway is still provisioning (can take 15-30 minutes)"
          echo "   2. Backend containers are not running or not healthy"
          echo "   3. Network Security Group rules may be blocking traffic"
          echo "   4. Application Gateway health probe configuration issue"
          echo ""
          echo "üí° To verify manually:"
          echo "   - Check Application Gateway status in Azure Portal"
          echo "   - Verify backend health: az network application-gateway show-backend-health"
          echo "   - Check if containers are running on the VM"
          echo "   - Verify NSG rules allow traffic from Application Gateway subnet"
          exit 0  # Don't fail the workflow, just warn
